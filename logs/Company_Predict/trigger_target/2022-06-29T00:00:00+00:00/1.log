[2022-07-01 07:44:13,053] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 07:44:13,090] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 07:44:13,091] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 07:44:13,092] {taskinstance.py:1043} INFO - Starting attempt 1 of 1
[2022-07-01 07:44:13,093] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 07:44:13,108] {taskinstance.py:1063} INFO - Executing <Task(TriggerDagRunOperator): trigger_target> on 2022-06-29T00:00:00+00:00
[2022-07-01 07:44:13,113] {standard_task_runner.py:52} INFO - Started process 188 to run task
[2022-07-01 07:44:13,123] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'Company_Predict', 'trigger_target', '2022-06-29T00:00:00+00:00', '--job-id', '1531', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_predict.py', '--cfg-path', '/tmp/tmpejq9rnll', '--error-file', '/tmp/tmp5g2wczr4']
[2022-07-01 07:44:13,126] {standard_task_runner.py:77} INFO - Job 1531: Subtask trigger_target
[2022-07-01 07:44:13,178] {logging_mixin.py:104} INFO - Running <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [running]> on host 14dddcffc0ea
[2022-07-01 07:44:13,241] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique Liebana Peña
AIRFLOW_CTX_DAG_ID=Company_Predict
AIRFLOW_CTX_TASK_ID=trigger_target
AIRFLOW_CTX_EXECUTION_DATE=2022-06-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-29T00:00:00+00:00
[2022-07-01 07:44:13,279] {trigger_dagrun.py:140} INFO - Clearing SDG_Enrique_V0 on 2022-06-29T00:00:00+00:00
[2022-07-01 07:44:13,442] {trigger_dagrun.py:165} INFO - Waiting for SDG_Enrique_V0 on 2022-06-29 00:00:00+00:00 to become allowed state ['success'] ...
[2022-07-01 07:45:13,473] {trigger_dagrun.py:165} INFO - Waiting for SDG_Enrique_V0 on 2022-06-29 00:00:00+00:00 to become allowed state ['success'] ...
[2022-07-01 07:46:13,439] {trigger_dagrun.py:165} INFO - Waiting for SDG_Enrique_V0 on 2022-06-29 00:00:00+00:00 to become allowed state ['success'] ...
[2022-07-01 07:47:13,416] {trigger_dagrun.py:174} INFO - SDG_Enrique_V0 finished with allowed state success
[2022-07-01 07:47:13,429] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=Company_Predict, task_id=trigger_target, execution_date=20220629T000000, start_date=20220701T074413, end_date=20220701T074713
[2022-07-01 07:47:13,458] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-07-01 07:47:13,502] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-07-01 10:35:28,575] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 10:35:28,619] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 10:35:28,621] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 10:35:28,622] {taskinstance.py:1043} INFO - Starting attempt 1 of 1
[2022-07-01 10:35:28,623] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 10:35:28,644] {taskinstance.py:1063} INFO - Executing <Task(TriggerDagRunOperator): trigger_target> on 2022-06-29T00:00:00+00:00
[2022-07-01 10:35:28,660] {standard_task_runner.py:52} INFO - Started process 14919 to run task
[2022-07-01 10:35:28,682] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'Company_Predict', 'trigger_target', '2022-06-29T00:00:00+00:00', '--job-id', '1559', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_predict.py', '--cfg-path', '/tmp/tmpcs1gr9rw', '--error-file', '/tmp/tmpsrt9ixb1']
[2022-07-01 10:35:28,686] {standard_task_runner.py:77} INFO - Job 1559: Subtask trigger_target
[2022-07-01 10:35:28,933] {logging_mixin.py:104} INFO - Running <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [running]> on host 14dddcffc0ea
[2022-07-01 10:35:29,128] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique Liebana Peña
AIRFLOW_CTX_DAG_ID=Company_Predict
AIRFLOW_CTX_TASK_ID=trigger_target
AIRFLOW_CTX_EXECUTION_DATE=2022-06-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-29T00:00:00+00:00
[2022-07-01 10:35:29,335] {taskinstance.py:1455} ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.

[SQL: INSERT INTO dag_run (dag_id, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'SDG_Enrique_V0', 'execution_date': DateTime(2022, 6, 29, 0, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 7, 1, 10, 35, 29, 326264, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'manual__2022-06-29T00:00:00+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7f91c25f2490>, 'last_scheduling_decision': None, 'dag_hash': '416aa760e43189792114879ef11a2cae'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/trigger_dagrun.py", line 135, in execute
    replace_microseconds=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/api/common/experimental/trigger_dag.py", line 123, in trigger_dag
    replace_microseconds=replace_microseconds,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/api/common/experimental/trigger_dag.py", line 89, in _trigger_dag
    dag_hash=dag_bag.dags_hash.get(dag_id),
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1781, in create_dagrun
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.

[SQL: INSERT INTO dag_run (dag_id, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'SDG_Enrique_V0', 'execution_date': DateTime(2022, 6, 29, 0, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 7, 1, 10, 35, 29, 326264, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'manual__2022-06-29T00:00:00+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7f91c25f2490>, 'last_scheduling_decision': None, 'dag_hash': '416aa760e43189792114879ef11a2cae'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-07-01 10:35:29,393] {taskinstance.py:1503} INFO - Marking task as FAILED. dag_id=Company_Predict, task_id=trigger_target, execution_date=20220629T000000, start_date=20220701T103528, end_date=20220701T103529
[2022-07-01 10:35:29,467] {local_task_job.py:146} INFO - Task exited with return code 1
[2022-07-01 10:36:47,554] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 10:36:47,584] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [queued]>
[2022-07-01 10:36:47,585] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 10:36:47,586] {taskinstance.py:1043} INFO - Starting attempt 1 of 1
[2022-07-01 10:36:47,587] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-07-01 10:36:47,601] {taskinstance.py:1063} INFO - Executing <Task(TriggerDagRunOperator): trigger_target> on 2022-06-29T00:00:00+00:00
[2022-07-01 10:36:47,616] {standard_task_runner.py:52} INFO - Started process 15053 to run task
[2022-07-01 10:36:47,630] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'Company_Predict', 'trigger_target', '2022-06-29T00:00:00+00:00', '--job-id', '1568', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_predict.py', '--cfg-path', '/tmp/tmpfacz7zip', '--error-file', '/tmp/tmp48y0cwyt']
[2022-07-01 10:36:47,642] {standard_task_runner.py:77} INFO - Job 1568: Subtask trigger_target
[2022-07-01 10:36:47,753] {logging_mixin.py:104} INFO - Running <TaskInstance: Company_Predict.trigger_target 2022-06-29T00:00:00+00:00 [running]> on host 14dddcffc0ea
[2022-07-01 10:36:47,848] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique Liebana Peña
AIRFLOW_CTX_DAG_ID=Company_Predict
AIRFLOW_CTX_TASK_ID=trigger_target
AIRFLOW_CTX_EXECUTION_DATE=2022-06-29T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-06-29T00:00:00+00:00
[2022-07-01 10:36:47,949] {taskinstance.py:1455} ERROR - (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.

[SQL: INSERT INTO dag_run (dag_id, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'SDG_Enrique_V0', 'execution_date': DateTime(2022, 6, 29, 0, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 7, 1, 10, 36, 47, 934992, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'manual__2022-06-29T00:00:00+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7f91c25f2490>, 'last_scheduling_decision': None, 'dag_hash': '416aa760e43189792114879ef11a2cae'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UniqueViolation: duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1112, in _run_raw_task
    self._prepare_and_execute_task_with_callbacks(context, task)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1285, in _prepare_and_execute_task_with_callbacks
    result = self._execute_task(context, task_copy)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/taskinstance.py", line 1315, in _execute_task
    result = task_copy.execute(context=context)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/operators/trigger_dagrun.py", line 135, in execute
    replace_microseconds=False,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/api/common/experimental/trigger_dag.py", line 123, in trigger_dag
    replace_microseconds=replace_microseconds,
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/api/common/experimental/trigger_dag.py", line 89, in _trigger_dag
    dag_hash=dag_bag.dags_hash.get(dag_id),
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/utils/session.py", line 65, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.6/site-packages/airflow/models/dag.py", line 1781, in create_dagrun
    session.flush()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.6/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.IntegrityError: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_run_dag_id_execution_date_key"
DETAIL:  Key (dag_id, execution_date)=(SDG_Enrique_V0, 2022-06-29 00:00:00+00) already exists.

[SQL: INSERT INTO dag_run (dag_id, execution_date, start_date, end_date, state, run_id, creating_job_id, external_trigger, run_type, conf, last_scheduling_decision, dag_hash) VALUES (%(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(state)s, %(run_id)s, %(creating_job_id)s, %(external_trigger)s, %(run_type)s, %(conf)s, %(last_scheduling_decision)s, %(dag_hash)s) RETURNING dag_run.id]
[parameters: {'dag_id': 'SDG_Enrique_V0', 'execution_date': DateTime(2022, 6, 29, 0, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2022, 7, 1, 10, 36, 47, 934992, tzinfo=Timezone('UTC')), 'end_date': None, 'state': 'running', 'run_id': 'manual__2022-06-29T00:00:00+00:00', 'creating_job_id': None, 'external_trigger': True, 'run_type': <DagRunType.MANUAL: 'manual'>, 'conf': <psycopg2.extensions.Binary object at 0x7f91c25f2490>, 'last_scheduling_decision': None, 'dag_hash': '416aa760e43189792114879ef11a2cae'}]
(Background on this error at: http://sqlalche.me/e/13/gkpj)
[2022-07-01 10:36:48,002] {taskinstance.py:1503} INFO - Marking task as FAILED. dag_id=Company_Predict, task_id=trigger_target, execution_date=20220629T000000, start_date=20220701T103647, end_date=20220701T103647
[2022-07-01 10:36:48,091] {local_task_job.py:146} INFO - Task exited with return code 1
