[2022-06-26 17:55:16,927] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 17:55:16,957] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 17:55:16,958] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 17:55:16,959] {taskinstance.py:1043} INFO - Starting attempt 2 of 2
[2022-06-26 17:55:16,960] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 17:55:16,974] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): postgreSQL_getTable> on 2022-06-26T00:00:00+00:00
[2022-06-26 17:55:16,983] {standard_task_runner.py:52} INFO - Started process 28613 to run task
[2022-06-26 17:55:16,990] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'SDG_Enrique_V0', 'postgreSQL_getTable', '2022-06-26T00:00:00+00:00', '--job-id', '226', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_forecasting.py', '--cfg-path', '/tmp/tmp8ucuzhy9', '--error-file', '/tmp/tmp_5leww9o']
[2022-06-26 17:55:16,993] {standard_task_runner.py:77} INFO - Job 226: Subtask postgreSQL_getTable
[2022-06-26 17:55:17,074] {logging_mixin.py:104} INFO - Running <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [running]> on host 5e8dc4b25004
[2022-06-26 17:55:17,140] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique
AIRFLOW_CTX_DAG_ID=SDG_Enrique_V0
AIRFLOW_CTX_TASK_ID=postgreSQL_getTable
AIRFLOW_CTX_EXECUTION_DATE=2022-06-26T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-26T00:00:00+00:00
[2022-06-26 17:55:17,157] {base.py:74} INFO - Using connection to: id: postgres_conection. Host: host.docker.internal, Port: 5432, Schema: data_company, Login: airflow, Password: XXXXXXXX, extra: None
[2022-06-26 17:55:32,967] {company_forecasting.py:78} INFO - Backup Company data in : /raw_data/company.csv
[2022-06-26 17:55:32,969] {python.py:118} INFO - Done. Returned value was: None
[2022-06-26 17:55:32,981] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=SDG_Enrique_V0, task_id=postgreSQL_getTable, execution_date=20220626T000000, start_date=20220626T175516, end_date=20220626T175532
[2022-06-26 17:55:33,011] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-26 17:55:33,082] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-26 19:20:25,043] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 19:20:25,054] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 19:20:25,055] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 19:20:25,056] {taskinstance.py:1043} INFO - Starting attempt 2 of 2
[2022-06-26 19:20:25,056] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 19:20:25,069] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): postgreSQL_getTable> on 2022-06-26T00:00:00+00:00
[2022-06-26 19:20:25,077] {standard_task_runner.py:52} INFO - Started process 841 to run task
[2022-06-26 19:20:25,081] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'SDG_Enrique_V0', 'postgreSQL_getTable', '2022-06-26T00:00:00+00:00', '--job-id', '250', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_forecasting.py', '--cfg-path', '/tmp/tmpbdp3p_q0', '--error-file', '/tmp/tmpvzemo1e3']
[2022-06-26 19:20:25,083] {standard_task_runner.py:77} INFO - Job 250: Subtask postgreSQL_getTable
[2022-06-26 19:20:25,127] {logging_mixin.py:104} INFO - Running <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [running]> on host 6fc8504e86cf
[2022-06-26 19:20:25,163] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique
AIRFLOW_CTX_DAG_ID=SDG_Enrique_V0
AIRFLOW_CTX_TASK_ID=postgreSQL_getTable
AIRFLOW_CTX_EXECUTION_DATE=2022-06-26T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-26T00:00:00+00:00
[2022-06-26 19:20:25,174] {base.py:74} INFO - Using connection to: id: postgres_conection. Host: host.docker.internal, Port: 5432, Schema: data_company, Login: airflow, Password: XXXXXXXX, extra: None
[2022-06-26 19:20:39,948] {company_forecasting.py:78} INFO - Backup Company data in : /raw_data/company.csv
[2022-06-26 19:20:39,953] {python.py:118} INFO - Done. Returned value was: None
[2022-06-26 19:20:39,965] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=SDG_Enrique_V0, task_id=postgreSQL_getTable, execution_date=20220626T000000, start_date=20220626T192025, end_date=20220626T192039
[2022-06-26 19:20:39,994] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-26 19:20:40,030] {local_task_job.py:146} INFO - Task exited with return code 0
[2022-06-26 19:26:55,730] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 19:26:55,747] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [queued]>
[2022-06-26 19:26:55,748] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 19:26:55,749] {taskinstance.py:1043} INFO - Starting attempt 2 of 2
[2022-06-26 19:26:55,749] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2022-06-26 19:26:55,757] {taskinstance.py:1063} INFO - Executing <Task(PythonOperator): postgreSQL_getTable> on 2022-06-26T00:00:00+00:00
[2022-06-26 19:26:55,762] {standard_task_runner.py:52} INFO - Started process 648 to run task
[2022-06-26 19:26:55,766] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'SDG_Enrique_V0', 'postgreSQL_getTable', '2022-06-26T00:00:00+00:00', '--job-id', '292', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/company_forecasting.py', '--cfg-path', '/tmp/tmprvaauc5q', '--error-file', '/tmp/tmpvdvnqm7i']
[2022-06-26 19:26:55,769] {standard_task_runner.py:77} INFO - Job 292: Subtask postgreSQL_getTable
[2022-06-26 19:26:55,812] {logging_mixin.py:104} INFO - Running <TaskInstance: SDG_Enrique_V0.postgreSQL_getTable 2022-06-26T00:00:00+00:00 [running]> on host 6fc8504e86cf
[2022-06-26 19:26:55,858] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=enrique-liebana@outlook.com
AIRFLOW_CTX_DAG_OWNER=Enrique
AIRFLOW_CTX_DAG_ID=SDG_Enrique_V0
AIRFLOW_CTX_TASK_ID=postgreSQL_getTable
AIRFLOW_CTX_EXECUTION_DATE=2022-06-26T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-26T00:00:00+00:00
[2022-06-26 19:26:55,873] {base.py:74} INFO - Using connection to: id: postgres_conection. Host: host.docker.internal, Port: 5432, Schema: data_company, Login: airflow, Password: XXXXXXXX, extra: None
[2022-06-26 19:27:08,903] {company_forecasting.py:78} INFO - Backup Company data in : /raw_data/company.csv
[2022-06-26 19:27:08,904] {python.py:118} INFO - Done. Returned value was: None
[2022-06-26 19:27:08,915] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=SDG_Enrique_V0, task_id=postgreSQL_getTable, execution_date=20220626T000000, start_date=20220626T192655, end_date=20220626T192708
[2022-06-26 19:27:08,942] {taskinstance.py:1220} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-06-26 19:27:08,977] {local_task_job.py:146} INFO - Task exited with return code 0
